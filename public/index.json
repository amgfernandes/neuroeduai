
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    [{"authors":["admin"],"categories":null,"content":" I am an experienced data scientist fascinated by the analysis of data, using AI/ML methods to gain valuable insights and improve decision-making. Aiming to empower people through knowledge!\nCurrently, I am using AI tools to help people get the best possible medical treatment.\nIn addition, I love communicating with diverse audiences, teaching, and to work in a team to solve complex problems. I am also a strong supporter of open-source tools, accessible to people around the world to tackle their challenges.\n \n“Education is the most powerful weapon which you can use to change the world.” -Nelson Mandela ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"http://localhost:1313/author/miguel-fernandes/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/miguel-fernandes/","section":"authors","summary":" I am an experienced data scientist fascinated by the analysis of data, using AI/ML methods to gain valuable insights and improve decision-making. Aiming to empower people through knowledge!\nCurrently, I am using AI tools to help people get the best possible medical treatment.\n","tags":null,"title":"Miguel Fernandes","type":"authors"},{"authors":null,"categories":null,"content":"Using an available library for feature selection based on Genetic algorithm feature selection (sklearn-genetic-opt)\nThe idea is to make it generic and easy to use with the terminal and with logging possibility. A GUI with Napari is planned as next project\nSee below Repository link\nRepository Link Feature selection GA_based_feature_selection Genetic algorithms (GA) Feature Selection based on sklearn-genetic-opt https://sklearn-genetic-opt.readthedocs.io/en/stable/index.html#sklearn-genetic-opt\nParser for command-line options is implemented\nInstall Example with new environment named feature_selection\nconda create -n feature_selection -y conda activate feature_selection conda install pip -y pip install -r requirements.txt Script: GA_based_selection.py\nRun in the terminal:\nFor help: python GA_based_selection.py -h\nRun with: python GA_based_selection.py with the appropriate arguments\nExample:\npython GA_based_selection.py -g 5 -p 10 -c 0.2 -m 12 Arguments: \u0026#39;--generations\u0026#39;, \u0026#39;-g\u0026#39;, default=5 \u0026#39;--population_size\u0026#39;, \u0026#39;-p\u0026#39;, default=8 \u0026#39;--crossover_probability\u0026#39;, \u0026#39;-c\u0026#39;, default=0.1 \u0026#39;--max_features\u0026#39;, \u0026#39;-m\u0026#39;, default=10 Notes: A log file and csv files are generated with parameters and selected features. Some plots for evaluation are also created.\n","date":1662595200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1662595200,"objectID":"eb587630462fb6e8f7f40a539f55431e","permalink":"http://localhost:1313/post/feature-selection/","publishdate":"2022-09-08T00:00:00Z","relpermalink":"/post/feature-selection/","section":"post","summary":"Using an available library for feature selection based on Genetic algorithm feature selection (sklearn-genetic-opt)\nThe idea is to make it generic and easy to use with the terminal and with logging possibility. A GUI with Napari is planned as next project\n","tags":["genetic algorithms","feature","python"],"title":"Feature selection","type":"post"},{"authors":null,"categories":null,"content":"Introduction to Bioimage analysis for Master of Science (M.Sc.) in Neurosciences.\nSee repository for details\nSee below Repository link\nRepository Link Introduction to Bioimage analysis FIJI Clij2 GPU Weka ML course Introduction to Bioimage analysis for Master of Science (M.Sc.) in Neurosciences\nIn preparation for the course please install in advance: FIJI: https://imagej.net/software/fiji/ Python/Anaconda installation (optional): https://docs.anaconda.com/anaconda/install/ Download or use Git to clone this repository: You can use Download ZIP or Git: git clone https://github.com/amgfernandes/FIJI_Clij2_GPU_Weka_ML_course.git\nFor the python part: You can create a new environment called bioimage:\ncd python_visualization conda create --name bioimage -y conda activate bioimage conda install pip -y pip install -r requirements.txt And add your new env kernel to your jupyter\nconda install -c anaconda ipykernel python -m ipykernel install --user --name=bioimage Bioimage Analysis: Recommended Reading and Viewing: Python: Basics for Data Scientists –\u0026gt; https://github.com/FabrizioMusacchio/Python_Course Introduction to Bioimage Analysis –\u0026gt; https://bioimagebook.github.io/README.html Introduction to Bioimage Analysis video –\u0026gt; https://www.ibiology.org/techniques/introduction-to-bioimage-analysis/ Bioimage analysis for computational biology –\u0026gt; https://github.com/BiAPoL/Bio-image_Analysis_with_Python Introduction to Image Analysis with FIJI –\u0026gt; https://www.crick.ac.uk/sites/default/files/2018-07/Introduction%20to%20image%20analysis%20with%20FIJI_David%20Berry_TheFrancisCrickInstitute_0.pdf ML for Bioimage analysis –\u0026gt; https://montpellierressourcesimagerie.github.io/mri-workshop-machine-learning/slides_day1.revealjs.htm#/3 ","date":1662595200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1662595200,"objectID":"8ddcb272faead056a2afbab64ceda52b","permalink":"http://localhost:1313/post/introduction-to-bioimage-analysis-/","publishdate":"2022-09-08T00:00:00Z","relpermalink":"/post/introduction-to-bioimage-analysis-/","section":"post","summary":"Introduction to Bioimage analysis for Master of Science (M.Sc.) in Neurosciences.\nSee repository for details\nSee below Repository link\nRepository Link Introduction to Bioimage analysis FIJI Clij2 GPU Weka ML course Introduction to Bioimage analysis for Master of Science (M.Sc.) in Neurosciences\n","tags":["bioimage analysis","python"],"title":"Introduction to Bioimage analysis for Master of Science in Neurosciences","type":"post"},{"authors":["Yvonne Kölsch","Joshua Hahn","Anna Sappington","Manuel Stemmer","António M. Fernandes","Thomas O. Helmbrecht","Shriya Lele","Salwan Butrus","Eva Laurell","Irene Arnold-Ammer","Karthik Shekhar","Joshua R. Sanes","Herwig Baier"],"categories":[],"content":"","date":1606780800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609239558,"objectID":"e2fe0211bfc7968671d925f8ab411075","permalink":"http://localhost:1313/publication/kolsch-molecular-2020/","publishdate":"2020-12-29T10:59:17.713204Z","relpermalink":"/publication/kolsch-molecular-2020/","section":"publication","summary":"Retinal ganglion cells (RGCs) form an array of feature detectors, which convey visual information to central brain regions. Characterizing RGC diversity is required to understand the logic of the underlying functional segregation. Using single-cell transcriptomics, we systematically classified RGCs in adult and larval zebrafish, thereby identifying marker genes for textgreater30 mature types and several developmental intermediates. We used this dataset to engineer transgenic driver lines, enabling specific experimental access to a subset of RGC types. Expression of one or few transcription factors often predicts dendrite morphologies and axonal projections to specific tectal layers and extratectal targets. In vivo calcium imaging revealed that molecularly defined RGCs exhibit specific functional tuning. Finally, chemogenetic ablation of eomesa+ RGCs, which comprise melanopsin-expressing types with projections to a small subset of central targets, selectively impaired phototaxis. Together, our study establishes a framework for systematically studying the functional architecture of the visual system.","tags":["\"behavior\"","\"cell atlas\"","\"eomes\"","\"genetic markers\"","\"genome engineering\"","\"ipRGCs\"","\"physiology\"","\"single-cell transcriptomics\"","\"visual pathways\""],"title":"Molecular classification of zebrafish retinal ganglion cells links genes to cell types to behavior","type":"publication"},{"authors":["António M. Fernandes","Duncan S. Mearns","Joseph C. Donovan","Johannes Larsch","Thomas O. Helmbrecht","Yvonne Kölsch","Eva Laurell","Koichi Kawakami","Marco dal Maschio","Herwig Baier"],"categories":[],"content":"","date":1606780800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609239557,"objectID":"4068e3ee110b7e0c59b2cce769c9e784","permalink":"http://localhost:1313/publication/fernandes-neural-2020/","publishdate":"2020-12-29T10:59:16.880302Z","relpermalink":"/publication/fernandes-neural-2020/","section":"publication","summary":"When navigating the environment, animals need to prioritize responses to the most relevant stimuli. Although a theoretical framework for selective visual attention exists, its circuit implementation has remained obscure. Here we investigated how larval zebrafish select between simultaneously presented visual stimuli. We found that a mix of winner-take-all (WTA) and averaging strategies best simulates behavioral responses. We identified two circuits whose activity patterns predict the relative saliencies of competing visual objects. Stimuli presented to only one eye are selected by WTA computation in the inner retina. Binocularly presented stimuli, on the other hand, are processed by reciprocal, bilateral connections between the nucleus isthmi (NI) and the tectum. This interhemispheric computation leads to WTA or averaging responses. Optogenetic stimulation and laser ablation of NI neurons disrupt stimulus selection and behavioral action selection. Thus, depending on the relative locations of competing stimuli, a combination of retinotectal and isthmotectal circuits enables selective visual attention.","tags":["\"behavioral choice\"","\"isthmotectal\"","\"nucleus isthmi\"","\"parabigeminal nucleus\"","\"retinotectal\"","\"saliency\"","\"stimulus selection\"","\"visual system\""],"title":"Neural circuitry for stimulus selection in the zebrafish visual system","type":"publication"},{"authors":null,"categories":null,"content":"Can we find identify functionally distinct neurons by using clustering and linear regression?\nAnswer: Yes. This approach reveals functionally distinct neuronal classes. See below Notebook or Repository link\nRepository Link Neuronal imaging Brief description of the approach to answer the question:\nInspired by Miri et al., 2011, a regressor-based ROI analysis of the imaging data was performed.\nRegressors are generated with time series that are set to zero for all time points except the time points of stimulation, which are set to one (visual stimuli in this case are Prey-like, Looming and Dimming). The regressors are then convolved with a kernel describing the GCaMP response function.\nA linear regression approach (using Python scikit-learn) was used to select neurons, removing neurons with activity not locked to stimulus presentation (spontaneously active).\nExtracted neurons were clustered using hierarchical clustering (agglomerative approach with Python scipy.cluster.hierarchy.linkage) for visualization of response types.\nThe maximum score of either the prey-like stimuli (nasalward and temporalward), looming or dimming stimuli was used to assign ROIs to specific response types.\nReferences:\nMiri, A., Daie, K., Burdine, R.D., Aksay, E., and Tank, D.W. (2011). Regression-based identification of behavior-encoding neurons during large-scale optical imaging of neural activity at cellular resolution. J. Neurophysiol. 105, 964–980.\nAntónio M. Fernandes, Johannes Larsch, Joseph C. Donovan, Thomas O. Helmbrecht, Duncan Mearns, Yvonne Kölsch, Marco Dal Maschio, Herwig Baier bioRxiv 598383; doi: https://doi.org/10.1101/598383\nRelated to Fernandes et. al 2019: Neuronal circuitry for stimulus selection in the visual system.\nSome of the helper functions were written with the help of Joe Donovan (https://github.com/joe311), Vilim Štih(https://github.com/vilim) and Thomas Helmbrecht.\n__author__ = \u0026#39;Fernandes\u0026#39; %load_ext autoreload %autoreload 2 ###################### IMPORT LIBRARIES################################ \u0026#39;\u0026#39;\u0026#39; import os from Miguel_load_exp_Femtonics_python3 import * import matplotlib.pyplot as plt import numpy as np from filepicker_python3 import * import shelve import time import seaborn as sns import pickle import sys from sklearn import linear_model, metrics from filepicker_python3 import pickfiles from ipywidgets import interact from helper_functions_imaging import * \u0026#39;\u0026#39;\u0026#39;Region of sensor used (GCaMP)\u0026#39;\u0026#39;\u0026#39; GCaMP = \u0026#39;gcamp6s\u0026#39; \u0026#39;\u0026#39;\u0026#39;Region of the brain imaged\u0026#39;\u0026#39;\u0026#39; regions=[\u0026#39;right_tectum\u0026#39;] #can run over multiple regions \u0026#39;\u0026#39;\u0026#39; ###################### Loading The Files ####################### \u0026#39;\u0026#39;\u0026#39; reg_path=(\u0026#39;/Users/fernandes/Dropbox (Personal)/Github_Migas/Neuronal_imaging/example_ROIs.p\u0026#39;) print (reg_path) /Users/fernandes/Dropbox (Personal)/Github_Migas/Neuronal_imaging/example_ROIs.p for region in regions: \u0026#39;\u0026#39;\u0026#39;Load files\u0026#39;\u0026#39;\u0026#39; print (region) print (\u0026#39;Loading...\u0026#39;) tload1 = time.time() Exp_MF = load_experiment_w_pickle_new_femtonics_2019(reg_path, corrected=False) tload2 = time.time() tload = tload2 - tload1 print (\u0026#39;Done - Time for Image Loading:\u0026#39;, tload) print (\u0026#39;Image - Dimensions:\u0026#39;, np.shape(Exp_MF.images)) try: filename = Exp_MF.metadata[\u0026#39;Experiment code\u0026#39;]+\u0026#39;_\u0026#39;+Exp_MF.metadata[\u0026#39;Fish name\u0026#39;]+\u0026#39;_\u0026#39;+Exp_MF.metadata[\u0026#39;Recording name\u0026#39;]+\u0026#39;_\u0026#39;+Exp_MF.metadata[\u0026#39;Visual Stim\u0026#39;] except: filename = Exp_MF.metadata[\u0026#39;Experiment code\u0026#39;]+\u0026#39;_\u0026#39;+Exp_MF.metadata[\u0026#39;Fish name\u0026#39;]+\u0026#39;_\u0026#39;+Exp_MF.metadata[\u0026#39;Recording name\u0026#39;]+\u0026#39;_\u0026#39;+Exp_MF.metadata[\u0026#39;Visual Stimulation\u0026#39;] filename_dir = os.path.dirname(reg_path) +\u0026#39;/\u0026#39;+ filename \u0026#39;\u0026#39;\u0026#39;Take shelve file with extracted ROIs\u0026#39;\u0026#39;\u0026#39; curr_path=str(os.path.dirname(reg_path)) os.chdir(curr_path) file_shelve = os.path.dirname(reg_path) + \u0026#39;/\u0026#39; + Exp_MF.metadata[\u0026#39;Recording name\u0026#39;].replace(\u0026#34;M\u0026#34;, \u0026#34;F\u0026#34;)+\u0026#39;_UGf_ROIs\u0026#39;+\u0026#39;_\u0026#39;+ str(region)+\u0026#39;.shv\u0026#39; shelvename = file_shelve analysed_shv = shelve.open(os.path.basename(os.path.normpath(file_shelve)), protocol=2) ROI_settings = analysed_shv[\u0026#39;settings\u0026#39;] #if shelve cannot be read pass everything and move on to next file metadata = Exp_MF.metadata #take metadata protocol = Exp_MF.stimuli frame_rate = float(1 / Exp_MF.dt) \u0026#39;\u0026#39;\u0026#39;which GCaMP used?\u0026#39;\u0026#39;\u0026#39; if GCaMP == \u0026#39;gcamp6s\u0026#39;: print (\u0026#39;GCamP6s used\u0026#39;) exp_decay_kernel = Exp_MF.exp_decay_kernel_g6s() if GCaMP == \u0026#39;gcamp6f\u0026#39;: exp_decay_kernel = Exp_MF.exp_decay_kernel_g6f() \u0026#39;\u0026#39;\u0026#39; ###################### Building Regressors ##################################################################### \u0026#39;\u0026#39;\u0026#39; stim1_main=np.where(Exp_MF.stimuli[\u0026#39;stim1_presence\u0026#39;]\u0026gt;0) stim2_main=np.where(Exp_MF.stimuli[\u0026#39;stim2_presence\u0026#39;]\u0026gt;0) stim3_main=np.where(Exp_MF.stimuli[\u0026#39;stim3_presence\u0026#39;]\u0026gt;0) t=Exp_MF.stimuli[\u0026#39;t\u0026#39;] #t is time from protocol file reg_stim1=make_reg(regressor_to_make=stim1_main, steps=Exp_MF.steps,t=t,frame_rate=frame_rate) reg_stim2=make_reg(regressor_to_make=stim2_main, steps=Exp_MF.steps,t=t,frame_rate=frame_rate) reg_stim3=make_reg(regressor_to_make=stim3_main, steps=Exp_MF.steps,t=t,frame_rate=frame_rate) reg_stim1_high = find_timepoints_reg_high(reg_stim1) reg_stim2_high = …","date":1593043200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593043200,"objectID":"aeb27123226551b3a0a21f5993510e4d","permalink":"http://localhost:1313/post/neuronal_imaging/","publishdate":"2020-06-25T00:00:00Z","relpermalink":"/post/neuronal_imaging/","section":"post","summary":"Can we find identify functionally distinct neurons by using clustering and linear regression?\nAnswer: Yes. This approach reveals functionally distinct neuronal classes. See below Notebook or Repository link\nRepository Link Neuronal imaging ","tags":["clustering","linear regression","python"],"title":"Imaging analysis of neuronal activity","type":"post"},{"authors":null,"categories":null,"content":"Can we use clustering to find meaningful insights when zebrafish are faced with two competing threatening stimuli?\nAnswer: No. This approach does not reveal distinct response types.Clustering is NOT a good approach for this behavioral data. Boundaries seem arbitrary.\nSee below Notebook or Repository link\nTrying out clustering on behavioral decisions of zebrafish when they are faced with two competing threatening stimuli. This data is related to the following publication: Neuronal circuitry for stimulus selection in the visual system.\nRepository Link Clustering import pandas as pd import matplotlib.pyplot as plt import numpy as np import seaborn as sns import scipy.stats as sta from itertools import groupby import os import glob %reload_ext autoreload %autoreload 2 %matplotlib inline import sys print(\u0026#34;Python version\u0026#34;) print (sys.version) Python version 3.7.2 (default, Dec 29 2018, 00:00:04) [Clang 4.0.1 (tags/RELEASE_401/final)] Specify file containing behavioral data df=pd.read_csv(\u0026#39;MF319_competition_3_conditions_df_.csv\u0026#39;, index_col=0) df.head() animalID c1 c2 condition e expAnimal experiment frame frameCont l ... yp2 treatment xOriginal yOriginal front right left r centerDist lastStep 0 0.0 1.0 0.0 4 1.0 0.0 0.0 0.0 2800.0 0.0 ... 0.630044 0 235.0 430.0 0.0 0.0 0.0 -0.000000 0.0 0.0 1 0.0 1.0 0.0 4 1.0 0.0 0.0 1.0 2801.0 0.0 ... 0.630044 0 235.0 430.0 0.0 0.0 0.0 -0.000000 0.0 0.0 2 0.0 1.0 0.0 4 1.0 0.0 0.0 2.0 2802.0 0.0 ... 0.630044 0 234.0 430.0 1.0 0.0 1.0 1.834389 1.0 1.0 3 0.0 1.0 0.0 4 1.0 0.0 0.0 3.0 2803.0 0.0 ... 0.630044 0 234.0 430.0 1.0 0.0 1.0 1.834389 1.0 0.0 4 0.0 1.0 0.0 4 1.0 0.0 0.0 4.0 2804.0 0.0 ... 0.630044 0 234.0 430.0 1.0 0.0 1.0 1.834389 1.0 0.0 5 rows × 31 columns\ndf.columns Index([\u0026#39;animalID\u0026#39;, \u0026#39;c1\u0026#39;, \u0026#39;c2\u0026#39;, \u0026#39;condition\u0026#39;, \u0026#39;e\u0026#39;, \u0026#39;expAnimal\u0026#39;, \u0026#39;experiment\u0026#39;, \u0026#39;frame\u0026#39;, \u0026#39;frameCont\u0026#39;, \u0026#39;l\u0026#39;, \u0026#39;o\u0026#39;, \u0026#39;s1\u0026#39;, \u0026#39;s1b\u0026#39;, \u0026#39;s2\u0026#39;, \u0026#39;s2b\u0026#39;, \u0026#39;trial\u0026#39;, \u0026#39;x\u0026#39;, \u0026#39;xp1\u0026#39;, \u0026#39;xp2\u0026#39;, \u0026#39;y\u0026#39;, \u0026#39;yp1\u0026#39;, \u0026#39;yp2\u0026#39;, \u0026#39;treatment\u0026#39;, \u0026#39;xOriginal\u0026#39;, \u0026#39;yOriginal\u0026#39;, \u0026#39;front\u0026#39;, \u0026#39;right\u0026#39;, \u0026#39;left\u0026#39;, \u0026#39;r\u0026#39;, \u0026#39;centerDist\u0026#39;, \u0026#39;lastStep\u0026#39;], dtype=\u0026#39;object\u0026#39;) df.condition.unique() array([4, 7, 1]) df.trial.max() 300.0 #specify time limits for analysis, i.e. to exclude very late trials first_trial=0 last_trial=300 #pull only trials within time limits dfEarly=df[(df.trial\u0026lt;last_trial)\u0026amp;(df.trial\u0026gt;first_trial)] #generate a unique ID from animalID and trial number dfEarly.loc[:,\u0026#39;anTrial\u0026#39;]=dfEarly.trial.values + dfEarly.animalID.values*dfEarly.trial.values.max() # #only consider animals that moved by more than a threshold ResponseThreshold=30 #should be around 4mm according to calculations. ind=(dfEarly.centerDist\u0026gt;=ResponseThreshold)\u0026amp;(dfEarly.frame\u0026lt;=dfEarly.frame.max()) d=dfEarly[ind] last_frame_stim=15 #last frame for looming presentation for each tRial. End of expansion #condition 1 is coNdition with right stimu only #condition 4 is coNdition with left stimu only #condition 7 is coNdition with both stimuli (equal stim competition) x_right_stim=d.x[(d.condition==1)\u0026amp;(d.frame==last_frame_stim)] y_right_stim=d.y[(d.condition==1)\u0026amp;(d.frame==last_frame_stim)] x_left_stim=d.x[(d.condition==4)\u0026amp;(d.frame==last_frame_stim)] y_left_stim=d.y[(d.condition==4)\u0026amp;(d.frame==last_frame_stim)] x_competition=d.x[(d.condition==7)\u0026amp;(d.frame==last_frame_stim)] y_competition=d.y[(d.condition==7)\u0026amp;(d.frame==last_frame_stim)] right_stim=np.stack([x_right_stim,y_right_stim]) left_stim=np.stack([x_left_stim,y_left_stim]) both_stim=np.stack([x_competition,y_competition]) \u0026#39;\u0026#39;\u0026#39;Condition with right or left stimuli alone\u0026#39;\u0026#39;\u0026#39; fig = plt.figure(figsize= (10, 10)) plt.scatter(right_stim[0],right_stim[1], color=\u0026#39;g\u0026#39;,label=\u0026#39;right loom\u0026#39;) plt.scatter(left_stim[0],left_stim[1], color=\u0026#39;m\u0026#39;,label=\u0026#39;left loom\u0026#39;) plt.legend(loc=\u0026#39;upper right\u0026#39;) plt.xlim(-200,200) plt.ylim(-200,200) sns.despine() \u0026#39;\u0026#39;\u0026#39;Condition with both stimuli\u0026#39;\u0026#39;\u0026#39; fig = plt.figure(figsize= (10, 10)) plt.scatter(both_stim[0],both_stim[1], color=\u0026#39;k\u0026#39;, label= \u0026#39;Both stim\u0026#39;) plt.legend(loc=\u0026#39;upper right\u0026#39;) plt.xlim(-200,200) plt.ylim(-200,200) sns.despine() Trying KMeans clustering Checking which K to use from sklearn.cluster import KMeans X=np.transpose(both_stim) #transpose to match what is expected for fit Sum_of_squared_distances = [] K = range(1,15) for k in K: km = KMeans(n_clusters=k) km = km.fit(X) Sum_of_squared_distances.append(km.inertia_) plt.plot(K, Sum_of_squared_distances, \u0026#39;bx-\u0026#39;) plt.xlabel(\u0026#39;k\u0026#39;) plt.ylabel(\u0026#39;Sum_of_squared_distances\u0026#39;) plt.title(\u0026#39;Elbow Method For Optimal k\u0026#39;) plt.show() kmeans = KMeans(n_clusters=4) kmeans.fit(X) y_kmeans = kmeans.predict(X) fig = plt.figure(figsize= (10, 10)) plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=50, cmap=\u0026#39;viridis\u0026#39;) centers = kmeans.cluster_centers_ plt.scatter(centers[:, 0], centers[:, 1], c=\u0026#39;black\u0026#39;, s=200, alpha=1, marker=\u0026#39;x\u0026#39;); plt.xlim(-200,200) plt.ylim(-200,200) (-200, 200) Testing Gaussian mixture model probability distribution Based on https://jakevdp.github.io/PythonDataScienceHandbook/05.12-gaussian-mixtures.html\nfrom sklearn import mixture gmm = mixture.GaussianMixture(n_components=4).fit(X) labels = gmm.predict(X) fig = …","date":1590105600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590105600,"objectID":"a41afbc6ec155d8f086f486f72b1d992","permalink":"http://localhost:1313/post/clustering/","publishdate":"2020-05-22T00:00:00Z","relpermalink":"/post/clustering/","section":"post","summary":"Can we use clustering to find meaningful insights when zebrafish are faced with two competing threatening stimuli?\nAnswer: No. This approach does not reveal distinct response types.Clustering is NOT a good approach for this behavioral data. Boundaries seem arbitrary.\n","tags":["clustering","machine learning","python"],"title":"Analysing behavioral data using clustering","type":"post"},{"authors":["Duncan S. Mearns","Joseph C. Donovan","António M. Fernandes","Julia L. Semmelhack","Herwig Baier"],"categories":[],"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609239552,"objectID":"dc566b989d712f61fcd52b9f52af153b","permalink":"http://localhost:1313/publication/mearns-deconstructing-2020/","publishdate":"2020-12-29T10:59:12.369406Z","relpermalink":"/publication/mearns-deconstructing-2020/","section":"publication","summary":"Animal behavior often forms sequences, built from simple stereotyped actions and shaped by environmental cues. A comprehensive characterization of the interplay between an animal’s movements and its environment is necessary to understand the sensorimotor transformations performed by the brain. Here, we use unsupervised methods to study behavioral sequences in zebraﬁsh larvae. We generate a map of swim bouts, revealing that ﬁsh modulate their tail movements along a continuum. During prey capture, larvae produce stereotyped sequences using a subset of bouts from a broader behavioral repertoire. These sequences exhibit loworder transition dynamics and immediately respond to changes in visual cues. Chaining of prey capture bouts is disrupted in visually impaired (lakritz and blumenkohl) mutants, and removing the prey stimulus during ongoing behavior in closed-loop virtual reality causes larvae to immediately abort the hunting sequence. These results suggest that the continuous integration of sensory information is necessary to structure the behavior. This stimulus-response loop serves to bring prey into the anterior dorsal visual ﬁeld of the larvae. Fish then release a capture strike maneuver comprising a stereotyped jaw movement and tail movements ﬁne-tuned to the distance of the prey. Fish with only one intact eye fail to correctly position the prey in the strike zone, but are able to produce the strike itself. Our analysis shows that short-term integration of binocular visual cues shapes the behavioral dynamics of hunting, thus uncovering the temporal organization of a goal-directed behavior in a vertebrate.","tags":[],"title":"Deconstructing Hunting Behavior Reveals a Tightly Coupled Stimulus-Response Loop","type":"publication"},{"authors":["Michael Kunst","Eva Laurell","Nouwar Mokayes","Anna Kramer","Fumi Kubo","António M. Fernandes","Dominique Förster","Marco Dal Maschio","Herwig Baier"],"categories":[],"content":"","date":1561939200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609239553,"objectID":"b63c8fbe168b97f2e4c603e22ad31f70","permalink":"http://localhost:1313/publication/kunst-cellular-resolution-2019/","publishdate":"2020-12-29T10:59:13.18846Z","relpermalink":"/publication/kunst-cellular-resolution-2019/","section":"publication","summary":"Understanding brain-wide neuronal dynamics requires a detailed map of the underlying circuit architecture. We built an interactive cellular-resolution atlas of the zebraﬁsh brain at 6 days post-fertilization (dpf) based on the reconstructions of over 2,000 individually GFP-labeled neurons. We clustered our dataset in ‘‘morphotypes,’’ establishing a unique database of quantitatively described neuronal morphologies together with their spatial coordinates in vivo. Over 100 transgene expression patterns were imaged separately and co-registered with the single-neuron atlas. By annotating 72 non-overlapping brain regions, we generated from our dataset an inter-areal wiring diagram of the larval brain, which serves as ground truth for synapse-scale, electron microscopic reconstructions. Interrogating our atlas by ‘‘virtual tract tracing’’ has already revealed previously unknown wiring principles in the tectum and the cerebellum. In conclusion, we present here an evolving computational resource and visualization tool, which will be essential to map function to structure in a vertebrate brain.","tags":[],"title":"A Cellular-Resolution Atlas of the Larval Zebrafish Brain","type":"publication"},{"authors":["Yinth Andrea Bernal Sierra","Benjamin R. Rost","Martin Pofahl","António Miguel Fernandes","Ramona A. Kopton","Sylvain Moser","Dominik Holtkamp","Nicola Masala","Prateep Beed","John J. Tukker","Silvia Oldani","Wolfgang Bönigk","Peter Kohl","Herwig Baier","Franziska Schneider-Warme","Peter Hegemann","Heinz Beck","Reinhard Seifert","Dietmar Schmitz"],"categories":[],"content":"","date":1543622400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609239554,"objectID":"0900d3a418be60a483fb659dc9a3fa63","permalink":"http://localhost:1313/publication/bernal-sierra-potassium-2018/","publishdate":"2020-12-29T10:59:13.63223Z","relpermalink":"/publication/bernal-sierra-potassium-2018/","section":"publication","summary":"","tags":[],"title":"Potassium channel-based optogenetic silencing","type":"publication"},{"authors":null,"categories":null,"content":" This website is created with Hugo. Hugo is a static site generator and does not collect, store, or process any personal information. Hugo GDPR options were set so that IP address is anonymous within Google Analytics and the “Do Not Track” request is set to true.\nThe use of this website does not require any cookies to be stored on your device. You can learn here how to disable all cookies: how to disable cookies.\nThird Party Inclusion\nThis website is hosted on Github. Github complies with the Privacy Shield Framework as described in their Global Privacy Practices.\n","date":1530140400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1530140400,"objectID":"18d05a63a1c8d7ed973cc51838494e41","permalink":"http://localhost:1313/privacy/","publishdate":"2018-06-28T00:00:00+01:00","relpermalink":"/privacy/","section":"","summary":" This website is created with Hugo. Hugo is a static site generator and does not collect, store, or process any personal information. Hugo GDPR options were set so that IP address is anonymous within Google Analytics and the “Do Not Track” request is set to true.\n","tags":null,"title":"Privacy Policy","type":"page"},{"authors":["Melanie Haehnel-Taguchi","António M. Fernandes","Margit Böhler","Ina Schmitt","Lena Tittel","Wolfgang Driever"],"categories":[],"content":"","date":1519862400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609239554,"objectID":"fc4f0b0832e250ab88864ee86d17bfc5","permalink":"http://localhost:1313/publication/haehnel-taguchi-projections-2018/","publishdate":"2020-12-29T10:59:14.080082Z","relpermalink":"/publication/haehnel-taguchi-projections-2018/","section":"publication","summary":"Dopaminergic neurons of the descending diencephalospinal system are located in the posterior tuberculum (PT) in zebraﬁsh (Danio rerio), and correspond in mammals to the A11 group in hypothalamus and thalamus. In the larval zebraﬁsh, they are likely the only source of central dopaminergic projections to the periphery. Here, we characterized posterior tubercular dopaminergic ﬁbers projecting to peripheral sense organs, with a focus on the lateral line neuromasts. We labeled and identiﬁed catecholaminergic neurons and their projections by combining two immunoﬂuorescence techniques, (i) using an antibody against Tyrosine hydroxylase, and (ii) using an antibody against GFP in transgenic zebraﬁsh expressing in catecholaminergic neurons either membrane-anchored GFP to track ﬁbers, or a Synaptophysin-GFP fusion to visualize putative synapses. We applied the CLARITY method to 6 days old whole zebraﬁsh larvae to stain and analyze dopaminergic projections by confocal microscopy. We found that all lateral line neuromasts receive direct innervation by posterior tubercular dopaminergic neurons, and tracked these projections in detail. In addition, we found dopaminergic ﬁbers projecting to the anterior and posterior lateral line ganglia, and extensive central dopaminergic arborizations around the terminal projection ﬁeld of the lateral line afferent neurons in the hindbrain medial octavolateralis nucleus (MON). Therefore, dopaminergic innervation may affect lateral line sense information at different processing stages. Additional dopaminergic ﬁbers innervate the trigeminal ganglion, and we observed ﬁne catecholaminergic ﬁbers in the skin with arborization patterns similar to free sensory nerve endings. We also detected potentially dopaminergic ﬁbers innervating inner ear sensory epithelia. Therefore, the diencephalospinal A11-type dopaminergic system may broadly modulate peripheral senses. We also brieﬂy report peripheral sympathetic catecholaminergic projections labeled in our experiments, and their innervation of the developing intestine, swim bladder and abdominal organs.","tags":[],"title":"Projections of the Diencephalospinal Dopaminergic System to Peripheral Sense Organs in Larval Zebrafish (Danio rerio)","type":"publication"},{"authors":["Dominique Förster","Irene Arnold-Ammer","Eva Laurell","Alison J. Barker","António M. Fernandes","Karin Finger-Baier","Alessandro Filosa","Thomas O. Helmbrecht","Yvonne Kölsch","Enrico Kühn","Estuardo Robles","Krasimir Slanchev","Tod R. Thiele","Herwig Baier","Fumi Kubo"],"categories":[],"content":"","date":1512086400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609239556,"objectID":"3f2e702fb6d10981a35e699fe45c3697","permalink":"http://localhost:1313/publication/forster-genetic-2017/","publishdate":"2020-12-29T10:59:16.198347Z","relpermalink":"/publication/forster-genetic-2017/","section":"publication","summary":"","tags":[],"title":"Genetic targeting and anatomical registration of neuronal populations in the zebrafish brain with a new set of BAC transgenic tools","type":"publication"},{"authors":["António M. Fernandes","Kandice Fero","Wolfgang Driever","Harold A. Burgess"],"categories":[],"content":"","date":1377993600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609239552,"objectID":"6424ebcbd1cddf317c5c14305e46e22a","permalink":"http://localhost:1313/publication/fernandes-enlightening-2013/","publishdate":"2020-12-29T10:59:12.046714Z","relpermalink":"/publication/fernandes-enlightening-2013/","section":"publication","summary":"","tags":[],"title":"Enlightening the brain: Linking deep brain photoreception with behavior and physiology: Insights \u0026 Perspectives","type":"publication"},{"authors":["António M. Fernandes","Erin Beddows","Alida Filippi","Wolfgang Driever"],"categories":[],"content":"","date":1377993600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609239556,"objectID":"c49479a5058e073b502f0ba8b70df624","permalink":"http://localhost:1313/publication/fernandes-orthopedia-2013/","publishdate":"2020-12-29T10:59:15.402319Z","relpermalink":"/publication/fernandes-orthopedia-2013/","section":"publication","summary":"The homeodomain transcription factor Orthopedia (Otp) is an important regulator for specification of defined subsets of neuroendocrine cells and dopaminergic neurons in vertebrates. In zebrafish, two paralogous otp genes, otpa and otpb, are present in the genome. Neither complete loss of Otp activity nor differential contributions of Otpa and Otpb to specification of defined neuronal populations have been analyzed in detail. We characterized zebrafish embryos and early larvae mutant for null alleles of otpa, otpb, or both genes to determine their individual contributions to the specification of th expressing dopaminergic neuronal populations as well as of crh, oxt, avp, trh or sst1.1 expressing neuroendocrine cells. otpa mutant larvae show an almost complete reduction of ventral diencephalic dopaminergic neurons, as reported previously. A small reduction in the number of trh cells in the preoptic region is detectable in otpa mutants, but no significant loss of crh, oxt and avp preoptic neuroendocrine cells. otpb single mutant larvae do not display a reduction in dopaminergic neurons or neuroendocrine cells in the otp expressing regions. In contrast, in otpa and otpb double mutant larvae specific groups of dopaminergic neurons as well as of crh, oxt, avp, trh and sst1.1-expressing neuroendocrine cells are completely lost. These observations suggest that the requirement for otpa and otpb function during development of the larval diencephalon is partially redundant. During evolutionary diversification of the paralogous otp genes, otpa maintained the prominent role in ventral diencephalic dopaminergic and neuroendocrine cell specification and is capable of partially compensating otpb loss of function. In addition, we identified a role of Otp in the development of a domain of somatostatin1-expressing cells in the rostral hindbrain, a region with strong otp expression but so far uncharacterized Otp function. Otp may thus be crucial for defined neuronal cell types also in the hindbrain.","tags":[],"title":"Orthopedia Transcription Factor otpa and otpb Paralogous Genes Function during Dopaminergic and Neuroendocrine Cell Specification in Larval Zebrafish","type":"publication"},{"authors":["António M. Fernandes","Kandice Fero","Aristides B. Arrenberg","Sadie A. Bergeron","Wolfgang Driever","Harold A. Burgess"],"categories":[],"content":"","date":1351728000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609239555,"objectID":"3f2115a7855b3c70165bc6f4ed25bc31","permalink":"http://localhost:1313/publication/fernandes-deep-2012/","publishdate":"2020-12-29T10:59:15.017759Z","relpermalink":"/publication/fernandes-deep-2012/","section":"publication","summary":"Most vertebrates process visual information using elaborately structured photosensory tissues, including the eyes and pineal. However, there is strong evidence that other tissues can detect and respond to photic stimuli [1–3]. Many reports suggest that photosensitive elements exist within the brain itself and inﬂuence physiology and behavior; however, a long-standing puzzle has been the identity of the neurons and photoreceptor molecules involved [4, 5]. We tested whether light cues inﬂuence behavior in zebraﬁsh larvae through deep brain photosensors. We found that larvae lacking eyes and pineal perform a simple light-seeking behavior triggered by loss of illumination (‘‘dark photokinesis’’). Neuroanatomical considerations prompted us to test orthopedia (otpa)-deﬁcient ﬁsh, which show a profound reduction in dark photokinesis. Using targeted genetic ablations, we narrowed the photosensitive region to neurons in the preoptic area. Neurons in this region express several photoreceptive molecules, but expression of the melanopsin opn4a is selectively lost in otpa mutants, suggesting that opn4a mediates dark photokinesis. Our ﬁndings shed light on the identity and function of deep brain photoreceptors and suggest that otpa speciﬁes an ancient population of sensory neurons that mediate behavioral responses to light.","tags":[],"title":"Deep Brain Photoreceptors Control Light-Seeking Behavior in Zebrafish Larvae","type":"publication"},{"authors":["Felix Schaller","Antonio M. Fernandes","Christine Hodler","Claudia Münch","Juan J. Pasantes","Wolfram Rietschel","Werner Schempp"],"categories":[],"content":"","date":1283299200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609239553,"objectID":"78c18a08067d94f3e28a7a864455f117","permalink":"http://localhost:1313/publication/schaller-y-2010/","publishdate":"2020-12-29T10:59:12.711117Z","relpermalink":"/publication/schaller-y-2010/","section":"publication","summary":"The male-specific regions of the Y chromosome (MSY) of the human and the chimpanzee (Pan troglodytes) are fully sequenced. The most striking difference is the dramatic rearrangement of large parts of their respective MSYs. These nonrecombining regions include ampliconic gene families that are known to be important for male reproduction,and are consequently under significant selective pressure. However, whether the published Y-chromosomal pattern of ampliconic fertility genes is invariable within P. troglodytes is an open but fundamental question pertinent to discussions of the evolutionary fate of the Y chromosome in different primate mating systems. To solve this question we applied fluorescence in situ hybridisation (FISH) of testis-specific expressed ampliconic fertility genes to metaphase Y chromosomes of 17 chimpanzees derived from 11 wild-born males and 16 bonobos representing seven wild-born males. We show that of eleven P. troglodytes Y-chromosomal lines, ten Y-chromosomal variants were detected based on the number and arrangement of the ampliconic fertility genes DAZ (deleted in azoospermia) and CDY (chromodomain protein Y)—a so-far never-described variation of a species’ Y chromosome. In marked contrast, no variation was evident among seven Ychromosomal lines of the bonobo, P. paniscus, the chimpanzee’s closest living relative. Although, loss of variation of the Y chromosome in the bonobo by a founder effect or genetic drift cannot be excluded, these contrasting patterns might be explained in the context of the species’ markedly different social and mating behaviour. In chimpanzees, multiple males copulate with a receptive female during a short period of visible anogenital swelling, and this may place significant selection on fertility genes. In bonobos, however, female mate choice may make sperm competition redundant (leading to monomorphism of fertility genes), since ovulation in this species is concealed by the prolonged anogenital swelling, and because female bonobos can occupy high-ranking positions in the group and are thus able to determine mate choice more freely.","tags":[],"title":"Y Chromosomal Variation Tracks the Evolution of Mating Systems in Chimpanzee and Bonobo","type":"publication"},{"authors":["Claudia Münch","Stefan Kirsch","António MG Fernandes","Werner Schempp"],"categories":[],"content":"","date":1199145600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609239554,"objectID":"22e9e32b3aaa77e3d2907b5d9ba67d1c","permalink":"http://localhost:1313/publication/munch-evolutionary-2008/","publishdate":"2020-12-29T10:59:14.474053Z","relpermalink":"/publication/munch-evolutionary-2008/","section":"publication","summary":"Background: Segmental duplications (SDs) are euchromatic portions of genomic DNA (≥ 1 kb) that occur at more than one site within the genome, and typically share a high level of sequence identity (textgreater90%). Approximately 5% of the human genome is composed of such duplicated sequences. Here we report the detailed investigation of CHEK2 duplications. CHEK2 is a multiorgan cancer susceptibility gene encoding a cell cycle checkpoint kinase acting in the DNA-damage response signalling pathway. The continuous presence of the CHEK2 gene in all eukaryotes and its important role in maintaining genome stability prompted us to investigate the duplicative evolution and phylogeny of CHEK2 and its paralogs during anthropoid evolution. Results: To study CHEK2 duplicon evolution in anthropoids we applied a combination of comparative FISH and in silico analyses. Our comparative FISH results with a CHEK2 fosmid probe revealed the single-copy status of CHEK2 in New World monkeys, Old World monkeys and gibbons. Whereas a single CHEK2 duplication was detected in orangutan, a multi-site signal pattern indicated a burst of duplication in African great apes and human. Phylogenetic analysis of paralogous and ancestral CHEK2 sequences in human, chimpanzee and rhesus macaque confirmed this burst of duplication, which occurred after the radiation of orangutan and African great apes. In addition, we used inter-species quantitative PCR to determine CHEK2 copy numbers. An amplification of CHEK2 was detected in African great apes and the highest CHEK2 copy number of all analysed species was observed in the human genome. Furthermore, we detected variation in CHEK2 copy numbers within the analysed set of human samples. Conclusion: Our detailed analysis revealed the highly dynamic nature of CHEK2 duplication during anthropoid evolution. We determined a burst of CHEK2 duplication after the radiation of orangutan and African great apes and identified the highest CHEK2 copy number in human. In conclusion, our analysis of CHEK2 duplicon evolution revealed that SDs contribute to inter-species variation. Furthermore, our qPCR analysis led us to presume CHEK2 copy number variation in human, and molecular diagnostics of the cancer susceptibility gene CHEK2 inside the duplicated region might be hampered by the individual-specific set of duplicons.","tags":[],"title":"Evolutionary analysis of the highly dynamic CHEK2 duplicon in anthropoids","type":"publication"}]