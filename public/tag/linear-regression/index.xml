<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Linear Regression | Neuroeduai</title>
    <link>http://localhost:1313/tag/linear-regression/</link>
      <atom:link href="http://localhost:1313/tag/linear-regression/index.xml" rel="self" type="application/rss+xml" />
    <description>Linear Regression</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Thu, 25 Jun 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>http://localhost:1313/media/icon_hu_1b4bcfdf7d67b990.png</url>
      <title>Linear Regression</title>
      <link>http://localhost:1313/tag/linear-regression/</link>
    </image>
    
    <item>
      <title>Imaging analysis of neuronal activity</title>
      <link>http://localhost:1313/post/neuronal_imaging/</link>
      <pubDate>Thu, 25 Jun 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/neuronal_imaging/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Can we find identify functionally distinct neurons by using clustering and linear regression?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Answer: Yes. This approach reveals functionally distinct neuronal classes. See below Notebook or Repository link&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;repository-link&#34;&gt;Repository Link&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/amgfernandes/Imaging_analysis&#34;&gt; Neuronal imaging &lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Brief description of the approach to answer the question:&lt;/p&gt;
&lt;p&gt;Inspired by Miri et al., 2011, a regressor-based ROI analysis of the imaging data was performed.&lt;/p&gt;
&lt;p&gt;Regressors are generated with time series that are set to zero for all time points except the time points of stimulation, which are set to one (visual stimuli in this case are Prey-like, Looming and Dimming). The regressors are then convolved with a kernel describing the GCaMP response function.&lt;/p&gt;
&lt;p&gt;A linear regression approach (using Python scikit-learn) was used to select neurons, removing neurons with activity not locked to stimulus presentation (spontaneously active).&lt;/p&gt;
&lt;p&gt;Extracted neurons were clustered using hierarchical clustering (agglomerative approach with Python scipy.cluster.hierarchy.linkage) for visualization of response types.&lt;/p&gt;
&lt;p&gt;The maximum score of either the prey-like stimuli (nasalward and temporalward), looming or dimming stimuli was used to assign ROIs to specific response types.&lt;/p&gt;
&lt;p&gt;References:&lt;/p&gt;
&lt;p&gt;Miri, A., Daie, K., Burdine, R.D., Aksay, E., and Tank, D.W. (2011). Regression-based identification of behavior-encoding neurons during large-scale optical imaging of neural activity at cellular resolution. J. Neurophysiol. 105, 964–980.&lt;/p&gt;
&lt;p&gt;António M. Fernandes, Johannes Larsch, Joseph C. Donovan, Thomas O. Helmbrecht, Duncan Mearns, Yvonne Kölsch, Marco Dal Maschio, Herwig Baier bioRxiv 598383; doi: &lt;a href=&#34;https://doi.org/10.1101/598383&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1101/598383&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Related to Fernandes et. al 2019:
&lt;a href=&#34;https://www.biorxiv.org/content/10.1101/598383v1&#34;&gt; Neuronal circuitry for stimulus selection in the visual system&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Some of the helper functions were written with the help of Joe Donovan (&lt;a href=&#34;https://github.com/joe311%29&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/joe311)&lt;/a&gt;, Vilim Štih(&lt;a href=&#34;https://github.com/vilim&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/vilim&lt;/a&gt;) and Thomas Helmbrecht.&lt;/p&gt;
&lt;hr&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;__author__ = &#39;Fernandes&#39;
%load_ext autoreload
%autoreload 2
###################### IMPORT LIBRARIES################################ &#39;&#39;&#39;

import os
from Miguel_load_exp_Femtonics_python3 import *
import matplotlib.pyplot as plt
import numpy as np
from filepicker_python3 import *
import shelve
import time
import seaborn as sns
import pickle
import sys
from sklearn import linear_model, metrics  
from filepicker_python3 import pickfiles
from ipywidgets import interact
from helper_functions_imaging import *
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&#39;&#39;&#39;Region of sensor used (GCaMP)&#39;&#39;&#39;
GCaMP = &#39;gcamp6s&#39;


&#39;&#39;&#39;Region of the brain imaged&#39;&#39;&#39;
regions=[&#39;right_tectum&#39;] #can run over multiple regions
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&#39;&#39;&#39; ###################### Loading The Files ####################### &#39;&#39;&#39;
reg_path=(&#39;/Users/fernandes/Dropbox (Personal)/Github_Migas/Neuronal_imaging/example_ROIs.p&#39;)
print (reg_path)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;/Users/fernandes/Dropbox (Personal)/Github_Migas/Neuronal_imaging/example_ROIs.p
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;for region in regions:

    &#39;&#39;&#39;Load files&#39;&#39;&#39;
    print (region)
    print (&#39;Loading...&#39;)
    tload1 = time.time()
    Exp_MF = load_experiment_w_pickle_new_femtonics_2019(reg_path, corrected=False)
    tload2 = time.time()
    tload = tload2 - tload1
    print (&#39;Done - Time for Image Loading:&#39;, tload)
    print (&#39;Image - Dimensions:&#39;, np.shape(Exp_MF.images))
    try:
        filename = Exp_MF.metadata[&#39;Experiment code&#39;]+&#39;_&#39;+Exp_MF.metadata[&#39;Fish name&#39;]+&#39;_&#39;+Exp_MF.metadata[&#39;Recording name&#39;]+&#39;_&#39;+Exp_MF.metadata[&#39;Visual Stim&#39;]
    except:
        filename = Exp_MF.metadata[&#39;Experiment code&#39;]+&#39;_&#39;+Exp_MF.metadata[&#39;Fish name&#39;]+&#39;_&#39;+Exp_MF.metadata[&#39;Recording name&#39;]+&#39;_&#39;+Exp_MF.metadata[&#39;Visual Stimulation&#39;]
    filename_dir = os.path.dirname(reg_path) +&#39;/&#39;+ filename

    &#39;&#39;&#39;Take shelve file with extracted ROIs&#39;&#39;&#39;
    curr_path=str(os.path.dirname(reg_path))
    os.chdir(curr_path)
    file_shelve = os.path.dirname(reg_path) + &#39;/&#39; + Exp_MF.metadata[&#39;Recording name&#39;].replace(&amp;quot;M&amp;quot;, &amp;quot;F&amp;quot;)+&#39;_UGf_ROIs&#39;+&#39;_&#39;+ str(region)+&#39;.shv&#39;
    shelvename = file_shelve

    analysed_shv = shelve.open(os.path.basename(os.path.normpath(file_shelve)), protocol=2)

    ROI_settings = analysed_shv[&#39;settings&#39;] #if shelve cannot be read pass everything and move on to next file

    metadata = Exp_MF.metadata #take metadata
    protocol = Exp_MF.stimuli

    frame_rate = float(1 / Exp_MF.dt)

    &#39;&#39;&#39;which GCaMP used?&#39;&#39;&#39;
    if GCaMP == &#39;gcamp6s&#39;:
        print (&#39;GCamP6s used&#39;)
        exp_decay_kernel = Exp_MF.exp_decay_kernel_g6s()
    if GCaMP == &#39;gcamp6f&#39;:
        exp_decay_kernel = Exp_MF.exp_decay_kernel_g6f()


    &#39;&#39;&#39; ###################### Building Regressors ##################################################################### &#39;&#39;&#39;      

    stim1_main=np.where(Exp_MF.stimuli[&#39;stim1_presence&#39;]&amp;gt;0)
    stim2_main=np.where(Exp_MF.stimuli[&#39;stim2_presence&#39;]&amp;gt;0)
    stim3_main=np.where(Exp_MF.stimuli[&#39;stim3_presence&#39;]&amp;gt;0)

    t=Exp_MF.stimuli[&#39;t&#39;] #t is time from protocol file

    reg_stim1=make_reg(regressor_to_make=stim1_main, steps=Exp_MF.steps,t=t,frame_rate=frame_rate)
    reg_stim2=make_reg(regressor_to_make=stim2_main, steps=Exp_MF.steps,t=t,frame_rate=frame_rate)
    reg_stim3=make_reg(regressor_to_make=stim3_main, steps=Exp_MF.steps,t=t,frame_rate=frame_rate)

    reg_stim1_high = find_timepoints_reg_high(reg_stim1)
    reg_stim2_high = find_timepoints_reg_high(reg_stim2)
    reg_stim3_high = find_timepoints_reg_high(reg_stim3)
    reg_all_high=np.concatenate((reg_stim1_high[0],reg_stim2_high[0],reg_stim3_high[0]))


    &#39;&#39;&#39;Convolve regressors&#39;&#39;&#39;

    reg_stim1_conv = (Exp_MF.convolve_regressors(reg_stim1,exp_decay_kernel))
    reg_stim2_conv = (Exp_MF.convolve_regressors(reg_stim2,exp_decay_kernel))
    reg_stim3_conv = (Exp_MF.convolve_regressors(reg_stim3,exp_decay_kernel))


    reg_stim1_high = find_timepoints_reg_high(reg_stim1)
    reg_stim2_high = find_timepoints_reg_high(reg_stim2)
    reg_stim3_high = find_timepoints_reg_high(reg_stim3)


    &#39;&#39;&#39;remove ROIs based on regression that are not locked to any stim (regressors)&#39;&#39;&#39;
#https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html
    reg = linear_model.LinearRegression()


    analysed_shv[&#39;ROI_traces_deltaF_F0&#39;]=dFoverF_ROIs(analysed_shv[&#39;ROI_traces&#39;])
    ROIs_seed_deltaF_F0=analysed_shv[&#39;ROI_traces_deltaF_F0&#39;]
    regs_conv = np.asarray([reg_stim1_conv,reg_stim2_conv,reg_stim3_conv])
    regs_timepoints =  [reg_stim1_high,reg_stim2_high,reg_stim3_high] #timepoints for regressors

    r2_threshold=0.05#&#39;&#39;&#39;regression threshold for ROIs&#39;&#39;&#39;
    &#39;&#39;&#39;fit for all regressors and then take the r2, remove all ROIs that are not highly correlated&#39;&#39;&#39;
    idx,r2,coefs = filter_rois(regs_conv, ROIs_seed_deltaF_F0, r2_threshold,reg) #filter spontaneous away ROIs
    &#39;&#39;&#39;ROIs_seed_deltaF_F0[idx , :] #filtered ROIs&#39;&#39;&#39;
    activity_ROIs_filt=mean_for_timepoints_with_ROIs(ROIs_seed_deltaF_F0[idx , :], regs=regs_timepoints, how_long=5) #how many frames

    &#39;&#39;&#39;#if ROIs pass threshold&#39;&#39;&#39;

    if r2.max()&amp;gt;r2_threshold: #only if ROIS pass threshold of r2
        df_save=pd.DataFrame(activity_ROIs_filt)

        keys_stim = [&#39;prey&#39;, &#39;looming&#39;, &#39;dimming&#39;]
        df_save.columns=keys_stim
        df_metadata=pd.Series(metadata)


        &#39;&#39;&#39;filter neurons by class [idx,:]&#39;&#39;&#39;
        coef_stim1_filt=coefs[idx,:][:,0] #for prey
        coef_stim2_filt=coefs[idx,:][:,1] #for loomming
        coef_stim3_filt=coefs[idx,:][:,2] #for dimming

        max_correlation_values_found=max_correlation_values(coef_stim1_filt,coef_stim2_filt,coef_stim3_filt) #find maximum value for each regressor

        prey_rois=np.where(coef_stim1_filt==max_correlation_values_found)
        looming_rois=np.where(coef_stim2_filt==max_correlation_values_found)
        dimming_rois=np.where(coef_stim3_filt==max_correlation_values_found)

        prey_rois_to_save=ROIs_seed_deltaF_F0[idx][prey_rois]
        looming_rois_to_save=ROIs_seed_deltaF_F0[idx][looming_rois]
        dimming_rois_to_save=ROIs_seed_deltaF_F0[idx][dimming_rois]

        analysed_shv.close() #close shelve file


print (&#39;DONE ALL FILES&#39;)


&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;right_tectum
Loading...
Done - Time for Image Loading: 5.382801055908203
Image - Dimensions: (439, 345, 559)
GCamP6s used
DONE ALL FILES
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;metadata-from-experiment&#34;&gt;Metadata from experiment&lt;/h1&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;metadata
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;{&#39;Experiment code&#39;: &#39;MF343&#39;,
 &#39;Recording name&#39;: &#39;M4&#39;,
 &#39;Visual Stimulation&#39;: &#39;Prey vs Looming vs Dimming&#39;,
 &#39;Fish name&#39;: &#39;gad1bgalUAS NTRmch HucnlsG6s left eye PRE&#39;,
 &#39;Date_Time&#39;: &#39;d_20200117_ t_113240&#39;,
 &#39;Imaging time&#39;: &#39;420 sec&#39;,
 &#39;Imaging rate&#39;: &#39;1Hz 1 plane&#39;,
 &#39;Notes_&#39;: &#39;monocular&#39;}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;ROIs_seed_deltaF_F0
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;array([[1.30372351, 1.33589399, 1.35685345, ..., 0.22421512, 0.23576057,
        0.25036587],
       [0.68697448, 0.66299846, 0.73401614, ..., 0.12826612, 0.13901776,
        0.12742805],
       [0.6562971 , 0.59936269, 0.60723362, ..., 0.03472879, 0.03139012,
        0.02547576],
       ...,
       [0.27760876, 0.23184323, 0.22601176, ..., 0.08066913, 0.06958619,
        0.04749682],
       [0.11212086, 0.10181155, 0.11130001, ..., 0.04471489, 0.04416309,
        0.02516504],
       [0.06415005, 0.06092715, 0.06942013, ..., 0.04961192, 0.05060839,
        0.06207445]])
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&#39;&#39;&#39;Array of r2 scores&#39;&#39;&#39;
sns.distplot(r2)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;matplotlib.axes._subplots.AxesSubplot at 0x1a22a73470&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./Clustering_ROIs_example_7_1.png&#34; alt=&#34;png&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h1 id=&#34;clustering-all-neurons&#34;&gt;Clustering all neurons&lt;/h1&gt;
&lt;p&gt;White lines: stimulus presentation&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;result=sns.clustermap(ROIs_seed_deltaF_F0[:], metric=&amp;quot;correlation&amp;quot;, cmap=&amp;quot;mako&amp;quot;,col_cluster=False,\
   robust=True, figsize=(10,10), z_score=0,vmin=-1, vmax=3);
xposition = reg_all_high
ax = result.ax_heatmap
for xc in xposition:
    ax.axvline(x=xc, color=&#39;w&#39;, linestyle=&#39;--&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;/Users/fernandes/anaconda3/lib/python3.7/site-packages/seaborn/matrix.py:624: UserWarning: Clustering large matrix with scipy. Installing `fastcluster` may give better performance.
  warnings.warn(msg)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./Clustering_ROIs_example_9_1.png&#34; alt=&#34;png&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&#39;&#39;&#39;Save all Neurons&#39;&#39;&#39;
all_rois_df=pd.DataFrame(ROIs_seed_deltaF_F0)
all_rois_df.to_csv(&#39;all_rois_df.csv&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;clustering-selected-neurons&#34;&gt;Clustering selected neurons.&lt;/h1&gt;
&lt;p&gt;Removed neurons that are not locked to stimuli.
White lines: stimulus presentation&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;result=sns.clustermap(ROIs_seed_deltaF_F0[idx], metric=&amp;quot;correlation&amp;quot;, cmap=&amp;quot;mako&amp;quot;,col_cluster=False,\
   robust=True, figsize=(10,10), z_score=0,vmin=-1, vmax=3);    
ax = result.ax_heatmap
for xc in xposition:
    ax.axvline(x=xc, color=&#39;w&#39;, linestyle=&#39;--&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./Clustering_ROIs_example_12_0.png&#34; alt=&#34;png&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&#39;&#39;&#39;Save selected Neurons&#39;&#39;&#39;
rois_r2_pass=pd.DataFrame(ROIs_seed_deltaF_F0[idx])
rois_r2_pass
rois_r2_pass.to_csv(&#39;rois_r2_pass.csv&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&#39;&#39;&#39;Plot some example neurons&#39;&#39;&#39;
color_roi=[&#39;y&#39;,&#39;b&#39;,&#39;c&#39;,&#39;g&#39;,&#39;r&#39;]
for c, neuron in enumerate(ROIs_seed_deltaF_F0[idx][5:10]):
    plt.plot(neuron, color=color_roi[c])
    plt.xlabel(&#39;Time&#39;)
    plt.ylabel(&#39;Activity&#39;)
    sns.despine()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./Clustering_ROIs_example_14_0.png&#34; alt=&#34;png&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h1 id=&#34;check-all-selected-neurons&#34;&gt;Check all selected neurons&lt;/h1&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;@interact
def showTraces(roi:(0,ROIs_seed_deltaF_F0[idx].shape[0])):
    fig,ax =plt.subplots(figsize=(10,5))
    plt.plot(ROIs_seed_deltaF_F0[roi], color=&#39;k&#39;)
    p0=plt.plot(reg_stim1_conv, lw=1, color=&#39;orange&#39; )
    p1=plt.plot(reg_stim2_conv, lw=1, color=&#39;fuchsia&#39;)
    p2=plt.plot(reg_stim3_conv, lw=1, color=&#39;turquoise&#39;)
    ax.legend((p0[0], p1[0],p2[0]), (&#39;Prey&#39;, &#39;Looming&#39;, &#39;Dimming&#39;), bbox_to_anchor=(1,1))
    sns.despine()
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;interactive(children=(IntSlider(value=81, description=&#39;roi&#39;, max=163), Output()), _dom_classes=(&#39;widget-intera…
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;check-prey-responsive-neurons&#34;&gt;Check Prey-responsive neurons&lt;/h1&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;@interact
def showTraces(roi:(0,prey_rois_to_save.shape[0]-1)):
    fig,ax =plt.subplots(figsize=(10,5))
    p0=plt.plot(reg_stim1_conv, lw=1, color=&#39;orange&#39; )
    p1=plt.plot(reg_stim2_conv, lw=1, color=&#39;fuchsia&#39;)
    p2=plt.plot(reg_stim3_conv, lw=1, color=&#39;turquoise&#39;)
    ax.legend((p0[0], p1[0],p2[0]), (&#39;Prey&#39;, &#39;Looming&#39;, &#39;Dimming&#39;), bbox_to_anchor=(1,1))
    sns.despine()
    plt.plot(prey_rois_to_save[roi], color=&#39;k&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;interactive(children=(IntSlider(value=27, description=&#39;roi&#39;, max=54), Output()), _dom_classes=(&#39;widget-interac…
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;check-looming-responsive-neurons&#34;&gt;Check Looming-responsive neurons&lt;/h1&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from ipywidgets import interact
@interact
def showTraces(roi:(0,looming_rois_to_save.shape[0]-1)):
    fig,ax =plt.subplots(figsize=(10,5))
    p0=plt.plot(reg_stim1_conv, lw=1, color=&#39;orange&#39; )
    p1=plt.plot(reg_stim2_conv, lw=1, color=&#39;fuchsia&#39;)
    p2=plt.plot(reg_stim3_conv, lw=1, color=&#39;turquoise&#39;)
    ax.legend((p0[0], p1[0],p2[0]), (&#39;Prey&#39;, &#39;Looming&#39;, &#39;Dimming&#39;), bbox_to_anchor=(1,1))
    sns.despine()
    plt.plot(looming_rois_to_save[roi], color=&#39;k&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;interactive(children=(IntSlider(value=45, description=&#39;roi&#39;, max=91), Output()), _dom_classes=(&#39;widget-interac…
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;check-dimming-responsive-neurons&#34;&gt;Check Dimming-responsive neurons&lt;/h1&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from ipywidgets import interact
@interact
def showTraces(roi:(0,dimming_rois_to_save.shape[0]-1)):
    fig,ax =plt.subplots(figsize=(10,5))
    p0=plt.plot(reg_stim1_conv, lw=1, color=&#39;orange&#39; )
    p1=plt.plot(reg_stim2_conv, lw=1, color=&#39;fuchsia&#39;)
    p2=plt.plot(reg_stim3_conv, lw=1, color=&#39;turquoise&#39;)
    ax.legend((p0[0], p1[0],p2[0]), (&#39;Prey&#39;, &#39;Looming&#39;, &#39;Dimming&#39;), bbox_to_anchor=(1,1))
    sns.despine()
    plt.plot(dimming_rois_to_save[roi], color=&#39;k&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;interactive(children=(IntSlider(value=7, description=&#39;roi&#39;, max=15), Output()), _dom_classes=(&#39;widget-interact…
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
  </channel>
</rss>
